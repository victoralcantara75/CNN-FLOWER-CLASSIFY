{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-FLOWER-CLASSIFY.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "uH9NjMkn26cn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoralcantara75/CNN-FLOWER-CLASSIFY/blob/master/CNN_FLOWER_CLASSIFY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1DR8jRNE2pfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#CNN PARA CLASSIFICAÇÃO DE FLORES\n",
        "## SIN493 - DEEP LEARNING PARA VISÃO COMPUTACIONAL"
      ]
    },
    {
      "metadata": {
        "id": "uH9NjMkn26cn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##PYTORCH E CUDA"
      ]
    },
    {
      "metadata": {
        "id": "_4EkoQV63A14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#http://pytorch.org/\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zz-TL5vW3VH2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# verificando se o CUDA está disponível\n",
        "GPUavailable = torch.cuda.is_available()\n",
        "\n",
        "if GPUavailable:\n",
        "    print('Treinamento em GPU!')\n",
        "else:\n",
        "    print('Treinamento em CPU!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3JhvZaG8SXSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall -y Pillow\n",
        "!pip install Pillow==5.3.0\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcMY5X5s5Vjk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#IMPORTACOES NECESSARIAS\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MaDZNB-G52qu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##DATASET"
      ]
    },
    {
      "metadata": {
        "id": "QO-iPdhav54w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#BAIXANDO DATASET \n",
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_DRJvqoVkqj6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#PEGANDO DIRETORIO DO DATASET DE TREINO E TESTE\n",
        "diretorio_dados = 'flower_data'\n",
        "diretorio_treino = diretorio_dados + '/train'\n",
        "diretorio_validacao = diretorio_dados + '/valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hDMS6fDcpMF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# APLICANDO AS TRANSFORMACOES NECESSARIAS E O DATA AUGMENTATION\n",
        "\n",
        "transformacao_treino = transforms.Compose([ \n",
        "                       transforms.RandomRotation(10),      #ROTAÇÃO DAS IMAGENS\n",
        "                       transforms.RandomResizedCrop(224),  #INPUT SIZE 224X224\n",
        "                       transforms.RandomHorizontalFlip(),  #ESPELHAMENTO\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                ])\n",
        "transformacao_validacao = transforms.Compose([ \n",
        "                          transforms.Resize(224),\n",
        "                          transforms.RandomResizedCrop(224),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AbgHJNgHrb5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#PASSANDO OS DATASETS PARA OS VETORES (TREINO E TESTE)\n",
        "dados_treino = datasets.ImageFolder(diretorio_treino, transformacao_treino)\n",
        "dados_validacao = datasets.ImageFolder(diretorio_validacao, transformacao_validacao)\n",
        "\n",
        "print('Numero de imagens de treino: ', len(dados_treino))\n",
        "print('Numero de imagens de teste: ', len(dados_validacao))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSwVriMMz7sM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data Loaders e Visualização\n",
        "\n",
        "batch_size = 20\n",
        "num_workers=4\n",
        "\n",
        "#dataset_treino = datasets.ImageFolder(os.path.join(diretorio_dados), transformacao_treino)\n",
        "\n",
        "# dataloaders\n",
        "treino_loader = torch.utils.data.DataLoader(dados_treino, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "validacao_loader = torch.utils.data.DataLoader(dados_validacao, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
        "\n",
        "classes = dados_treino.classes\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tuMBGSQUsdo-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#MAPEANDO OS LABELS\n",
        "import json\n",
        "\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WI91k4168I1M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nomes_flores = [cat_to_name[classes[e]] for e in range (0, 101)]\n",
        "print(nomes_flores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1fzLjsRu7bCY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# obtendo um batch de imagens de treinamento\n",
        "dataiter = iter(treino_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy() # para exibir as imagens converter para numpy\n",
        "\n",
        "# plotar as imagens no batch, com os rótulos correspondentes\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u4-Nj6lRtiDe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TREINO E CLASSIFICACAO VGG"
      ]
    },
    {
      "metadata": {
        "id": "P42pC5YdtqEm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#criando o modelo de vgg 16 pre treinada\n",
        "VGG = models.vgg16(pretrained=True)\n",
        "#visualizacao da arquitetura utilizada vgg16\n",
        "print(VGG)\n",
        "\n",
        "# movendo os tensors para GPU se o CUDA estiver disponível\n",
        "if GPUavailable:\n",
        "    VGG.cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e0fEcw9M4o32",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Congelar o treinamento para todas as camadas de características\n",
        "for param in VGG.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "siWK3aco40s8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_inputs = VGG.classifier[6].in_features\n",
        "\n",
        "# adicionar a última camada para 102 classes\n",
        "# novas camadas automaticamente tem requires_grad = True\n",
        "last_layer = nn.Linear(n_inputs, 102)\n",
        "\n",
        "VGG.classifier[6] = last_layer\n",
        "\n",
        "# verifique se sua última camada produz o número esperado de saídas\n",
        "print(VGG.classifier[6].out_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Xuz2P_gyX72",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Especificando a loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Definindo o Otimizador\n",
        "optimizer = optim.SGD(VGG.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2o8kRTXWytNc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TREINAMENTO \n",
        "\n",
        "epocas = 3\n",
        "\n",
        "for epocas in range (1, epocas+1):\n",
        "\n",
        "  treino_loss = 0.0\n",
        "  \n",
        "  VGG.train()\n",
        "  for batch_i, (data, target) in enumerate(treino_loader):\n",
        "        \n",
        "        if GPUavailable:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        output = VGG(data)\n",
        "        loss = criterion(output, target)  #batch loss\n",
        "        loss.backward()\n",
        "        optimizer.step()                  #otimizador SGD \n",
        "        treino_loss += loss.item()        #atualizacao do treinamento\n",
        "        \n",
        "        if batch_i % 20 == 19:\n",
        "            print('Época %d, Batch %d loss: %.16f' % (epocas, batch_i + 1, treino_loss / 20))\n",
        "            treino_loss = 0.0\n",
        "        \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "38Hvd_mpKbRb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TESTE\n",
        "\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(102))\n",
        "class_total = list(0. for i in range(102))\n",
        "\n",
        "VGG.eval()\n",
        "\n",
        "for data, target in validacao_loader:\n",
        "    if GPUavailable:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "   \n",
        "    output = VGG(data)\n",
        "    loss = criterion(output, target)           #test loss\n",
        "    test_loss += loss.item()*data.size(0)      #atualizando loss\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))    #comparando respostas corretas\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not GPUavailable else np.squeeze(correct_tensor.cpu().numpy())\n",
        "   \n",
        "    # calculando acurácia do teste\n",
        "    for i in range(batch_size-2):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jFH3wK55xZvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculando avg teste loss\n",
        "test_loss = test_loss/len(validacao_loader.dataset)\n",
        "print('Teste Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(102):\n",
        "    if class_total[i] > 0:\n",
        "        print('Acurácia do teste classe %5s: %2d%% (%2d/%2d)' % (str(i), 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Acurácia do teste classe %5s: N/A (sem exemplos de treinamento')\n",
        "\n",
        "print('\\nAcurácia Total: %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P9RmzdWnh4_c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TREINO E CLASSIFICAÇÃO RESNET"
      ]
    },
    {
      "metadata": {
        "id": "Vcl85E4uh-0U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#criando o modelo de resnet pre treinada\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "#visualizacao da arquitetura utilizada resnet\n",
        "print(resnet)\n",
        "\n",
        "# movendo os tensors para GPU se o CUDA estiver disponível\n",
        "if GPUavailable:\n",
        "    resnet.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3N6PH7MwE3S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Especificando a loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Definindo o Otimizador\n",
        "optimizer = optim.SGD(resnet.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3NofH3S2i4Nm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TREINAMENTO \n",
        "\n",
        "epocas = 3\n",
        "\n",
        "resnet.train()\n",
        "for epocas in range (1, epocas+1):\n",
        "\n",
        "  treino_loss = 0.0\n",
        "  \n",
        " \n",
        "  for batch_i, (data, target) in enumerate(treino_loader):\n",
        "        \n",
        "        if GPUavailable:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        output = resnet(data)\n",
        "        loss = criterion(output, target)  #batch loss\n",
        "        loss.backward()\n",
        "        optimizer.step()                  #otimizador SGD \n",
        "        treino_loss += loss.item()        #atualizacao do treinamento\n",
        "        \n",
        "        if batch_i % 20 == 19:\n",
        "            print('Época %d, Batch %d loss: %.16f' % (epocas, batch_i + 1, treino_loss / 20))\n",
        "            treino_loss = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HGQPHqU2xW8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TESTE\n",
        "\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(102))\n",
        "class_total = list(0. for i in range(102))\n",
        "\n",
        "resnet.eval()\n",
        "\n",
        "for data, target in validacao_loader:\n",
        "    if GPUavailable:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "   \n",
        "    output = resnet(data)\n",
        "    loss = criterion(output, target)           #test loss\n",
        "    test_loss += loss.item()*data.size(0)      #atualizando loss\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))    #comparando respostas corretas\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not GPUavailable else np.squeeze(correct_tensor.cpu().numpy())\n",
        "   \n",
        "    # calculando acurácia do teste\n",
        "    for i in range(batch_size-2):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6dOVlzVzxijK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculando avg teste loss\n",
        "test_loss = test_loss/len(validacao_loader.dataset)\n",
        "print('Teste Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(102):\n",
        "    if class_total[i] > 0:\n",
        "        print('Acurácia do teste classe %5s: %2d%% (%2d/%2d)' % (str(i), 100 * class_correct[i] / class_total[i],np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Acurácia do teste classe %5s: N/A (sem exemplos de treinamento')\n",
        "\n",
        "print('\\nAcurácia Total: %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}