{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-FLOWER-CLASSIFY.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "uH9NjMkn26cn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoralcantara75/CNN-FLOWER-CLASSIFY/blob/master/CNN_FLOWER_CLASSIFY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1DR8jRNE2pfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#CNN PARA CLASSIFICAÇÃO DE FLORES\n",
        "## SIN493 - DEEP LEARNING PARA VISÃO COMPUTACIONAL"
      ]
    },
    {
      "metadata": {
        "id": "uH9NjMkn26cn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##PYTORCH E CUDA"
      ]
    },
    {
      "metadata": {
        "id": "_4EkoQV63A14",
        "colab_type": "code",
        "outputId": "072264a4-fd7d-4dcb-e94f-b051aa6418ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#http://pytorch.org/\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mfastai 1.0.42 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zz-TL5vW3VH2",
        "colab_type": "code",
        "outputId": "cf73aa25-b187-4c9c-dabe-d66963d76a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# verificando se o CUDA está disponível\n",
        "GPUavailable = torch.cuda.is_available()\n",
        "\n",
        "if GPUavailable:\n",
        "    print('Treinamento em GPU!')\n",
        "else:\n",
        "    print('Treinamento em CPU!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treinamento em GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MaDZNB-G52qu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##DATASET"
      ]
    },
    {
      "metadata": {
        "id": "U1u55XB556x1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LAzubFnJiYYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7d11975-5d70-40d8-e66f-8c6212755add"
      },
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "# import glob\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.image as mpimg\n",
        "# import numpy as np\n",
        "\n",
        "# PATH = '../train/'\n",
        "# listing = glob.glob(f'{PATH}*jpg')[:10];\n",
        "# listing\n",
        "\n",
        "# for images in listing :\n",
        "#   img = mpimg.inread(images);\n",
        "#   plt.figure();\n",
        "#   imgplot = plt.imshow(img)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "_DRJvqoVkqj6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = 'flower_data'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hDMS6fDcpMF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# APLICANDO AS TRANSFORMACOES NECESSARIAS E O DATA AUGMENTATION\n",
        "\n",
        "transformacao = {'train': \n",
        "                   transforms.Compose([ \n",
        "                   transforms.RandomRotation(10),      #ROTAÇÃO DAS IMAGENS\n",
        "                   transforms.RandomResizedCrop(224),  #INPUT SIZE 224X224\n",
        "                   transforms.RandomHorizontalFlip(),  #ESPELHAMENTO\n",
        "                   transforms.ToTensor(),\n",
        "                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                ]),\n",
        "                'valid': \n",
        "                   transforms.Compose([ \n",
        "                   transforms.Resize(256),\n",
        "                   transforms.CenterCrop(224),\n",
        "                   transforms.ToTensor(),\n",
        "                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                ])\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AbgHJNgHrb5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "image_datasets = {\n",
        "    x: datasets.ImageFolder(os.path.join(data_dir, x), transformacao[x])\n",
        "    for x in ['train', 'valid']\n",
        "}\n",
        "\n",
        "batch_size =4 \n",
        "\n",
        "dataloaders = {\n",
        "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, \n",
        "        shuffle=True, num_workers=4)\n",
        "    for x in ['train', 'valid']\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tuMBGSQUsdo-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#MAPEANDO OS LABELS\n",
        "import json\n",
        "\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u4-Nj6lRtiDe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##TREINO E CLASSIFICACAO VGG"
      ]
    },
    {
      "metadata": {
        "id": "P42pC5YdtqEm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "#criando o modelo de vgg 16 pre treinada\n",
        "VGG = models.vgg16(pretrained=True)\n",
        "#visualizacao da arquitetura utilizada vgg16\n",
        "VGG\n",
        "\n",
        "# movendo os tensors para GPU se o CUDA estiver disponível\n",
        "if GPUavailable:\n",
        "    VGG.cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Xuz2P_gyX72",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Especificando a loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Definindo o Otimizador\n",
        "optimizer = optim.SGD(VGG.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2o8kRTXWytNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "36822e95-573a-482a-89b1-da274fd30e92"
      },
      "cell_type": "code",
      "source": [
        "#TREINAMENTO \n",
        "\n",
        "epocas = 30\n",
        "\n",
        "for epocas in range (0, epocas):\n",
        "\n",
        "  treino_loss = 0.0\n",
        "  validacao_loss = 0.0\n",
        "  \n",
        "  VGG.train()\n",
        "  for data, target in image_datasets:\n",
        "    \n",
        "        if GPUavailable:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "          \n",
        "        optimizer.zero_grad()\n",
        "        output = VGG(data)\n",
        "        loss = criterion(output, target) #CALCULAR O LOSS\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*data.size(0) #ATUALIZAR O TRAINING LOSS\n",
        "        \n",
        "        \n",
        "  VGG.eval()\n",
        "  for data, target in dataloaders:\n",
        "    \n",
        "      if GPUavailable:\n",
        "          data, target = data.cuda(), target.cuda()\n",
        "          \n",
        "      output = VGG(data)\n",
        "      loss = criterion(output, target)\n",
        "      valid_loss += loss.item()*data.size(0)      \n",
        "\n",
        "      \n",
        "  # Calcular as perdas médias (losses)\n",
        "  treino_loss = train_loss/len(train_loader.dataset)\n",
        "  validacao_loss = valid_loss/len(valid_loader.dataset)\n",
        "  \n",
        "  # Impressão das estatísticas de treinamento/validação\n",
        "  print('Época: {} \\tTreinamento Loss: {:.6f} \\tValidacao Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
        "    \n",
        "  # Salvar o modelo se a perda da valiaçaõ tiver reduzido\n",
        "  if valid_loss <= valid_loss_min:\n",
        "      print('Validacao loss decrementou ({:.6f} --> {:.6f}).  Salvando o modelo ...'.format(\n",
        "      valid_loss_min,\n",
        "      valid_loss))\n",
        "      torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "      valid_loss_min = valid_loss"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-d0a8dc7c7aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mVGG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_datasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mGPUavailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jFH3wK55xZvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}